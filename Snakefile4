import os
from pathlib import Path
import pandas as pd
from scripts.pipeline import *

configfile: 'config/config.yaml'

cwd = Path.cwd()

print(config)
# Setup. Loading Accession, machine, chromosomes and haplotypes.
ACCESSION, MACHINE = glob_wildcards("downloads/{accession}_{machine}.fastq.gz")
ACCESSION, MACHINE = list(set(ACCESSION)), list(set(MACHINE))
FLANKING = [gene for chromosomes in config["FLANKING"].values() for region in chromosomes.values() for gene in region.values()]



wildcard_constraints:
    accession = "|".join(ACCESSION),
    machine = "|".join(MACHINE),

# Target rule specifying the desired final output
rule all:
    input:
        expand("final/all_outputs_{accession}_{machine}_chr{chrs}_hap{haplo}.txt", accession=ACCESSION, machine=MACHINE, chrs=config["CHROMOSOMES"], haplo=config["HAPLOTYPES"]),
        # expand("downloads/mmul10/chromosomes/mmul10_chr{chrs}.fasta", chrs=CHROMOSOMES),
        # expand("assembly/hifiasm/chr{chrs}/{accession}_chr{chrs}_hifiasmUL.bp.txt", chrs=CHROMOSOMES, accession=ACCESSION)
        # expand("flye/{chrs}_{accession}/assembly.fasta", chrs=["chr3", "chr7"], accession=ACCESSION),

rule downloadMmul10:
    output:
        ref_report = "downloads/mmul10/reports/mmul10_assembly_report.txt",
        ref = "downloads/mmul10/genome/mmul10.fna",
    params:
        zipped_ref = temp("downloads/mmul10/genome/mmul10.fna.gz")
    shell:
        """
        wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/003/339/765/GCA_003339765.3_Mmul_10/GCA_003339765.3_Mmul_10_assembly_report.txt -P reports -O {output.ref_report}
        wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/003/339/765/GCA_003339765.3_Mmul_10/GCA_003339765.3_Mmul_10_genomic.fna.gz -O {params.zipped_ref}
        gunzip {params.zipped_ref}
        """


rule splitChromosomes:
    input:
        fa = "downloads/mmul10/genome/mmul10.fna",
        report = ancient("downloads/mmul10/reports/mmul10_assembly_report.txt")
    output:
        fa = "downloads/mmul10/chromosomes/mmul10_chr{chrs}.fasta",
        temp = "downloads/mmul10/chromosomes/mmul10_chr{chrs}.txt"
    conda:
        "envs/seqkit.yaml"
    shell:
        """
        awk -F'\t' -v var={wildcards.chrs} '$1=="chr"var {{print $5}}' {input.report} > {output.temp}
        awk -F'\t' -v var={wildcards.chrs} '$1~"chr"var"_" {{print $5}}' {input.report} >> {output.temp}
        seqkit grep -f {output.temp} {input.fa} | sed "s/>/>chr{wildcards.chrs}_/g" > {output.fa}
        """

# Making new reference file.
rule newReferenceFile:
    input:
        expand("downloads/mmul10/chromosomes/mmul10_chr{chrs}.fasta", chrs = config["CHROMOSOMES"])
    output:
        "downloads/mmul10/genome/mmul10_new_ref.fasta"
    shell:
        """
        cat {input} > {output}
        """

# Checkpoint for dynamically splitting the FASTQ file
checkpoint split_fastq:
    input:
        fastq="downloads/{accession}_{machine}.fastq.gz"
    output:
        temp(directory("split_files/{accession}_{machine}"))
    conda:
        "envs/seqkit.yaml"
    shell:
        """
        # your shell commands for splitting the file
        mkdir -p {output}

        #run seqkit split2       
        seqkit split2 -s 1000000 -O {output} {input.fastq} 
        """


def getSplitFastqFiles(wildcards):
    checkpoint_output = checkpoints.split_fastq.get(accession=wildcards.accession, machine=wildcards.machine).output[0]
    parts = glob_wildcards(os.path.join(checkpoint_output, "{accession}_{machine}.part_{i}.fastq.gz")).i
    expanded_paths = expand("QC/raw/{accession}_{machine}.part_{i}.stats",
                            accession=wildcards.accession,
                            machine=wildcards.machine,
                            i=parts)
    return expanded_paths


# Rule for initial QC
rule seqkit:
    input:
        getSplitFastqFiles
    output:
        "results_{accession}.txt",
    shell:
        """
        cat {input} > {output}
        """

rule rawStats:
    input:
        "downloads/{accession}_{machine}.fastq.gz"
    output:
        "QC/raw/{accession}_{machine}.stats"
    conda:
        "envs/seqkit.yaml"
    shell:
        """
        seqkit stat {input} > {output}
        """

## Remove duplicate reads and filter reads
rule removeDuplicateReads:
    input:
        "split_files/{accession}_{machine}/{accession}_{machine}.part_{i}.fastq.gz"
    output:
        temp("filtered/no_duplicate_{accession}_{machine}.part_{i}.fastq.gz")
    log:
        "logs/seqkit/duplicates/log_{accession}_{machine}_duplicates.part_{i}.log"
    conda:
        "envs/seqkit.yaml"
    shell:
        """
        seqkit rmdup {input} -s -i -o {output} 2> {log}
        """


rule filteredReads:
    input:
        "filtered/no_duplicate_{accession}_{machine}.part_{i}.fastq.gz"
    output:
        temp("filtered/filtered_{accession}_{machine}.part_{i}.fastq.gz")
    log:
        "logs/seqkit/filterd/log_{accession}_{machine}_filterd.part_{i}.log"
    conda:
        "envs/seqkit.yaml"
    shell:
        """
        seqkit seq {input} -m 5000 -o {output} 2> {log}
        """

def getProcessedStatsFiles(wildcards):
    checkpoint_output = checkpoints.split_fastq.get(accession=wildcards.accession, machine=wildcards.machine).output[0]
    parts = glob_wildcards(f"{checkpoint_output}/{{accession}}_{{machine}}.part_{{i}}.fastq.gz").i
    expanded_paths = expand("QC/filtered/filtered_{accession}_{machine}.part_{i}.stats",
                            accession=wildcards.accession,
                            machine=wildcards.machine,
                            i=parts)
    return expanded_paths


rule processedStats:
    input:
        getProcessedStatsFiles
    output:
        "processed_{accession}.txt"
    shell:
        """
        cat {input} > {output}
        """


## Combine splitted files
def all_fastq_files(wildcards):
    checkpoint_output = checkpoints.split_fastq.get(accession=wildcards.accession, machine=wildcards.machine).output[0]
    expanded_paths = expand("filtered/filtered_{accession}_{machine}.part_{i}.fastq.gz",
                            accession=wildcards.accession,
                            machine=wildcards.machine,
                            i=glob_wildcards(os.path.join(checkpoint_output, "{accession}.part_{i}.fastq.gz")).i)
    return expanded_paths



rule combineFastQ:
    input:
        ancient(lambda wildcards: all_fastq_files(wildcards))
    output:
        temp("combined/{accession}_{machine}.combined.fastq.gz")
    shell:
        """
        cat {input} > {output}
        """


## Mapping, sorting, indexing
rule minimap2:
    input:
        read = ancient("combined/{accession}_{machine}.combined.fastq.gz"),
        mmul10 = ancient("downloads/mmul10/genome/mmul10_new_ref.fasta"),
    output:
        temp("alignments/{accession}_{machine}.sam")
    log:
        "logs/minimap2/log_{accession}_{machine}_alignment.log"
    benchmark:
        "benchmarks/minimap2/benchmark_{accession}_{machine}_alignment.txt"
    threads: 
        24
    params:
        read_type_pacbio = "map-hifi",
        read_type_nanopore = "map-ont"
    conda:
        "envs/minimap2.yaml"
    shell:
        """
        if [[ "{wildcards.machine}" == "pacbio" ]]; then
            minimap2 -ax {params.read_type_pacbio} -t {threads} {input.mmul10} {input.read} > {output} 2> {log}
        elif [[ "{wildcards.machine}" == "nanopore" ]]; then
            minimap2 -ax {params.read_type_nanopore} -t {threads} {input.mmul10} {input.read} > {output} 2> {log}
        fi
        """

rule extractMappedReads:
    input:
        ancient("alignments/{accession}_{machine}.sam")
    output:
        temp("alignments/extracted_{accession}_{machine}.bam")
    log:
        "logs/samtools/log_{accession}_{machine}_alignment.log",
    conda:
        "envs/samtools.yaml"
    threads:
        24
    shell:
        """
        samtools view -@ {threads} -bh {input} > {output} 2> {log}
        """

rule sortIndexBam:
    input:
        ancient("alignments/extracted_{accession}_{machine}.bam")
    output:
        sorted_bam = temp("alignments/sorted_{accession}_{machine}.bam"),
        index_bam = temp("alignments/sorted_{accession}_{machine}.bam.bai"),
    log:
        "logs/samtools/sort_index_log_{accession}_{machine}.log"
    conda:
        "envs/samtools.yaml"
    threads:
        10
    shell:
        """
        samtools sort -@ {threads} -o {output.sorted_bam} {input}
        samtools index -@ {threads} {output.sorted_bam} 2> {log}
        """


checkpoint separateChrs:
    input:
        bam = ancient("alignments/sorted_{accession}_{machine}.bam"),
        index_bam = temp("alignments/sorted_{accession}_{machine}.bam.bai"),
        temp = "downloads/mmul10/chromosomes/mmul10_chr{chrs}.txt"
    output:
        directory("temp/{accession}_{machine}_{chrs}")
    conda:
        "envs/samtools.yaml"
    threads: 
        8
    benchmark:
        "benchmarks/05_{accession}_{machine}_chr{chrs}.time"
    shell:
        """
        mkdir -p {output}
        for i in $(cat {input.temp}); do
            # Extract individual chrs
            samtools view -b {input.bam} "chr"{wildcards.chrs}"_"$i > {output}/$i".bam"
            #nummap=$(samtools view -h {output}/$i".bam" | grep -v "@" | wc -l || true)
            #if [[ $nummap == "0" ]]; then
            #    rm {output}/$i".bam"
            #fi
        done
        """

def combineChrFragments(wildcards):
    outdir = checkpoints.separateChrs.get(**wildcards).output[0]
    bams = glob_wildcards(os.path.join(outdir, "{bam}.bam")).bam
    return expand(os.path.join(outdir, "{bam}.bam"),
        bam = bams)

rule rejoinChrs:
    input:
        combineChrFragments
    output:
        temp("{accession}_{machine}_chr{chrs}.bam"),
    conda:
        "envs/samtools.yaml"
    threads: 
        8
    shell:
        """
        ulimit -Sn 4096
        samtools merge -@ {threads} -o {output} {input} 
        """

rule chrFastq:
    input:
        bam = "{accession}_{machine}_chr{chrs}.bam",
    output:
        "converted/chr{chrs}_{accession}_{machine}.fastq.gz",
    conda:
        "envs/samtools.yaml"
    threads: 
        8
    benchmark:
        "benchmarks/06_{accession}_{machine}_chr{chrs}_fastq.time"
    shell:
        """
        # Extract fastq
        samtools fastq -@ {threads} -0 {output} {input.bam}
        """




## Hifiasm ultra long assembly
rule hifiasmUlChromosomeAssembly:
    input:
        pacbio = ancient("converted/chr{chrs}_{accession}_pacbio.fastq.gz"),
        nanopore = ancient("converted/chr{chrs}_{accession}_nanopore.fastq.gz") 
    output:
        "assembly/hifiasm/chr{chrs}/{accession}_chr{chrs}_hifiasmUL.bp.hap1.p_ctg.gfa", 
        "assembly/hifiasm/chr{chrs}/{accession}_chr{chrs}_hifiasmUL.bp.hap2.p_ctg.gfa", 
    conda:
        "envs/hifiasm.yaml"
    log:
        "logs/assembly/hifiasm/log_hifiasmUL_chr{chrs}_{accession}.log"
    threads:
        24
    benchmark:
        "benchmarks/assembly_hifiasm_{accession}_chr{chrs}_hifiasmUL.time"
    shell:
        """
        hifiasm -o assembly/hifiasm/chr{wildcards.chrs}/{wildcards.accession}_chr{wildcards.chrs}_hifiasmUL -t {threads} --ul {input.nanopore}  {input.pacbio} 2> {log}
        """


rule gfaToFasta:
    input:
        "assembly/hifiasm/chr{chrs}/{accession}_chr{chrs}_hifiasmUL.bp.hap{haplo}.p_ctg.gfa"
    output:
        "converted/gfatofasta/chr{chrs}_{accession}_hap{haplo}.fasta"
    conda:
        "envs/gfatools.yaml"
    shell:
        """
        gfatools gfa2fa {input} > {output}       
        """

## improve contigs


# Quast
rule quastAssemblyStatistics:
    input:
        hap1 = ancient("converted/gfatofasta/chr{chrs}_{accession}_hap1.fasta"),
        hap2 = ancient("converted/gfatofasta/chr{chrs}_{accession}_hap2.fasta")
    output:
        directory("quast/hifiasm/chr{chrs}_{accession}")
    conda:
        "envs/quast.yaml"
    shell:
        """
        quast.py {input.hap1} {input.hap2} -o {output}
        """

# BUSCO
rule BUSCO:
    input:
        ancient("converted/gfatofasta/chr{chrs}_{accession}_hap{haplo}.fasta")
    output:
        directory("BUSCO/{accession}/chr{chrs}_{accession}_hap{haplo}")
    params:
        dataset = config["BUSCO_DATASET"]
    conda:
        "envs/busco.yaml"
    log:
        "logs/BUSCO/log_busco_chr{chrs}_{accession}_hap{haplo}.log"
    shell:
        """
        busco -i {input} -l {params.dataset} -o {output} -m genome 2> {log}
        """

# BUSCO mmul10
rule BUSCOReference:
    input:
        ancient("downloads/mmul10/chromosomes/mmul10_chr{chrs}.fasta")
    output:
        directory("BUSCO/mmul10/chr{chrs}")
    params:
        dataset = config["BUSCO_DATASET"]
    conda:
        "envs/busco.yaml"
    log:
        "logs/BUSCO/log_busco_mmul10_chr{chrs}.log"
    shell:
        """
        busco -i {input} -l {params.dataset} -o {output} -m genome 2> {log}
        """

# Inspector
rule inspector:
    input:
        pacbio = ancient("converted/chr{chrs}_{accession}_pacbio.fastq.gz"),
        nanopore = ancient("converted/chr{chrs}_{accession}_nanopore.fastq.gz"), 
        contig = ancient("converted/gfatofasta/chr{chrs}_{accession}_hap{haplo}.fasta")
    output:
        directory("inspector/chr{chrs}_{accession}_hap{haplo}")
    params:
        data_type = "mixed" 
    conda:
        "envs/inspector.yaml"
    shell:
        """
        inspector.py -c {input.contig} -r {input.pacbio} {input.nanopore} -o {output} --datatype {params.data_type}
        """


# Flanking genes
rule downloadFlankingGenes:
    output:
        "flanking/{fgene}/ncbi_dataset/data/gene.fna"
    conda:
        "envs/flanking.yaml"
    shell:
        """
        mkdir -p flanking/{wildcards.fgene}
        cd flanking/{wildcards.fgene}
        datasets download gene symbol {wildcards.fgene} --taxon macaca mulatta --include gene --filename {wildcards.fgene}.zip
        unzip {wildcards.fgene}.zip
        """



rule combineFlankingGenes:
    input:
        ancient(expand("flanking/{fgene}/ncbi_dataset/data/gene.fna", fgene=FLANKING))
    output:
        "flanking/all_flanking_genes.fna"
    shell:
        """
        > {output}
        for file in {input}; do
            header=$(head -1 "$file" | egrep "^>" | awk '{{print $2":" $5":"$NF}}' | tr -d '[]')
            sequence=$(cat "$file" | egrep -v "^>")
            echo -e ">$header\n$sequence" >> {output}
        done
        """


rule flankingByChromosomes:
    input:
        flanking = "flanking/all_flanking_genes.fna"
    params:
        chrs_id = "flanking/chr{chrs}_{accession}_flanking_genes_id.txt" 
    output:
        "flanking/chr{chrs}_{accession}_flanking_genes.fna"
    conda:
        "envs/seqtk.yaml"
    shell:
        """
        chromosome_number=$(echo "{wildcards.chrs}" | egrep -o "[0-9]")
        cat {input} | egrep "chromosome=$chromosome_number" | tr -d ">" > {params.chrs_id}
        seqtk subseq {input} {params.chrs_id} > {output}
        """


rule mapFlankingGenes:
    input:
        reads = ancient("converted/gfatofasta/chr{chrs}_{accession}_hap{haplo}.fasta"),
        flanking_genes = ancient("flanking/chr{chrs}_{accession}_flanking_genes.fna")
    output:
        sam_file = "flank_alignment/chr{chrs}_{accession}_hap{haplo}_aligned.sam",
    conda:
        "envs/minimap2.yaml"
    threads:
        6
    shell:
        """
        minimap2 -ax splice -t {threads} {input.reads} {input.flanking_genes} > {output.sam_file}
        """


## Generate regions
rule contigFiles:
    input:
        ancient("flank_alignment/chr{chrs}_{accession}_hap{haplo}_aligned.sam")
    output:
        touch("flank_alignment/chr{chrs}_{accession}_hap{haplo}_aligned.txt")
    conda:
        "envs/scripts.yaml"
    script:
        "scripts/region.py" 


rule combineRegion:
    input:
        expand("flank_alignment/chr{chrs}_{accession}_hap{haplo}_aligned.txt", chrs=config["CHROMOSOMES"], accession=ACCESSION, haplo=config["HAPLOTYPES"])
    output:
        temp("annotation/all_regions.txt")
    shell:
        """
        echo {input} | tr " " "\n" > {output}
        """

rule getLibrary:
    output:
        "library/library.fasta"
    params:
        species = config["LIBRARY"]["species"],
        cell_type = config["LIBRARY"]["cell_type"],
    conda:
        "envs/IMGT.yaml"
    shell:
        """
        python scripts/IMGT_scrape.py -S "{params.species}" -T {params.cell_type} --create-library --cleanup --simple-headers
        """
rule annotation:
    input:
        "annotation/all_regions.txt",
        "library/library.fasta"
    output:
        "annotation/annotation_report_plus.xlsx"
    conda:
        "envs/scripts.yaml"
    script:
        "scripts/annotation.py"


rule fetchAllInput:
    input:
        "annotation/annotation_report_plus.xlsx",
        "QC/raw/{accession}_{machine}.stats",
        "quast/hifiasm/chr{chrs}_{accession}",
        "BUSCO/{accession}/chr{chrs}_{accession}_hap{haplo}",
        "BUSCO/mmul10/chr{chrs}",
        "inspector/chr{chrs}_{accession}_hap{haplo}",
    output:
        touch("final/all_outputs_{accession}_{machine}_chr{chrs}_hap{haplo}.txt")


        
