import os
import pandas as pd
from scripts.pipeline import *
import json
current = os.getcwd()

ACCESSION, MACHINE = glob_wildcards("downloads/{accession}_{machine}.fastq.gz")
print(ACCESSION, MACHINE)
wildcard_constraints:
    accession = "|".join(ACCESSION),
    machine = "|".join(MACHINE)

with open("input/flanking_genes.txt", "r") as f:
    FLANKING_GENES = [gene.strip() for gene in f.readlines()]

print(FLANKING_GENES)
# Target rule specifying the desired final output
rule all:
    input:
        # expand("hifiasm/{chrs}_{accession}/", chrs=["chr3", "chr7"], accession=ACCESSION, machine=MACHINE),
        expand("final_{accession}_{machine}.txt", accession=ACCESSION, machine=MACHINE),
        "flanking/all_flanking_genes.fna"

rule downloadMmul10:
    output:
        ref_report = "downloads/reports/mmul10_assembly_report.txt",
        ref = "downloads/mmul10.fna",
    params:
        zipped_ref = "downloads/mmul10.fna.gz"
    shell:
        """
        wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/003/339/765/GCA_003339765.3_Mmul_10/GCA_003339765.3_Mmul_10_assembly_report.txt -P reports -O {output.ref_report}
        wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/003/339/765/GCA_003339765.3_Mmul_10/GCA_003339765.3_Mmul_10_genomic.fna.gz -O {params.zipped_ref}
        gunzip {params.zipped_ref}
        """

rule splitChromosomes:
    input:
       ref = "downloads/mmul10.fna"
    output:
        "downloads/{chrs}_mmul10.fna"
    shell:
        """
        chromosome=$(echo "{wildcards.chrs}" | egrep -o "[0-9]")
        awk -v chr="chromosome $chromosome" '$0 ~ chr {{print; while(getline > 0) {{ if (/^>/) {{ exit }} else {{ print }} }}}}' {input.ref} > {output}
        """ 

# Checkpoint to generate the JSON file
checkpoint generate_json:
    output:
        chr_conversion="input/chromosome_conversion.json",
        chr_length="input/chromosome_lengths.json"
    shell:
        """
        python -c "from scripts.pipeline import cal_chr_length; cal_chr_length()"
        python -c "from scripts.pipeline import fetch_chromosome; fetch_chromosome()"
        """


# Function to load JSON file into a Python dictionary
def load_json_file(input_file):
    with open(input_file, 'r') as f:
        return json.load(f)


# Checkpoint for dynamically splitting the FASTQ file
checkpoint split_fastq:
    input:
        fastq="downloads/{accession}_{machine}.fastq.gz"
    output:
        temp(directory("split_files/{accession}_{machine}"))
    conda:
        "envs/seqkit.yaml"
    shell:
        """
        # your shell commands for splitting the file
        mkdir -p {output}

        #run seqkit split2       
        seqkit split2 -s 1000000 -O {output} {input.fastq} 
        """


def getSplitFastqFiles(wildcards):
    checkpoint_output = checkpoints.split_fastq.get(accession=wildcards.accession, machine=wildcards.machine).output[0]
    parts = glob_wildcards(os.path.join(checkpoint_output, "{accession}_{machine}.part_{i}.fastq.gz")).i
    expanded_paths = expand("QC/raw/{accession}_{machine}.part_{i}.stats",
                            accession=wildcards.accession,
                            machine=wildcards.machine,
                            i=parts)
    return expanded_paths


rule rawStats:
    input:
        "downloads/{accession}_{machine}.fastq.gz"
    output:
        "QC/raw/{accession}_{machine}.stats"
    conda:
        "envs/seqkit.yaml"
    shell:
        """
        seqkit stat {input} > {output}
        """

# Rule for initial QC
rule seqkit:
    input:
        getSplitFastqFiles
    output:
        "results_{accession}.txt",
    shell:
        """
        cat {input} > {output}
        """


rule removeDuplicateReads:
    input:
        "split_files/{accession}_{machine}/{accession}_{machine}.part_{i}.fastq.gz"
    output:
        temp("filtered/no_duplicate_{accession}_{machine}.part_{i}.fastq.gz")
    log:
        "logs/seqkit/duplicates/log_{accession}_{machine}_duplicates.part_{i}.log"
    conda:
        "envs/seqkit.yaml"
    shell:
        """
        seqkit rmdup {input} -s -i -o {output} 2> {log}
        """


rule filteredReads:
    input:
        "filtered/no_duplicate_{accession}_{machine}.part_{i}.fastq.gz"
    output:
        temp("filtered/filtered_{accession}_{machine}.part_{i}.fastq.gz")
    log:
        "logs/seqkit/filterd/log_{accession}_{machine}_filterd.part_{i}.log"
    conda:
        "envs/seqkit.yaml"
    shell:
        """
        seqkit seq {input} -m 5000 -o {output} 2> {log}
        """

def getProcessedStatsFiles(wildcards):
    checkpoint_output = checkpoints.split_fastq.get(accession=wildcards.accession, machine=wildcards.machine).output[0]
    parts = glob_wildcards(f"{checkpoint_output}/{{accession}}_{{machine}}.part_{{i}}.fastq.gz").i
    expanded_paths = expand("QC/filtered/filtered_{accession}_{machine}.part_{i}.stats",
                            accession=wildcards.accession,
                            machine=wildcards.machine,
                            i=parts)
    return expanded_paths


rule processedStats:
    input:
        getProcessedStatsFiles
    output:
        "processed_{accession}.txt"
    shell:
        """
        cat {input} > {output}
        """


# Function to generate chromosome-specific BAM file paths
def all_fastq_files(wildcards):
    checkpoint_output = checkpoints.split_fastq.get(accession=wildcards.accession, machine=wildcards.machine).output[0]
    expanded_paths = expand("filtered/filtered_{accession}_{machine}.part_{i}.fastq.gz",
                            accession=wildcards.accession,
                            machine=wildcards.machine,
                            i=glob_wildcards(os.path.join(checkpoint_output, "{accession}.part_{i}.fastq.gz")).i)
    return expanded_paths



rule combineFastQ:
    input:
        ancient(lambda wildcards: all_fastq_files(wildcards))
    output:
        temp("combined/{accession}_{machine}.combined.fastq.gz")
    shell:
        """
        cat {input} > {output}
        """

rule seqkitFiltered:
    input:
        ancient("combined/{accession}_{machine}.combined.fastq.gz")
    output:
        "QC/filtered/filtered_{accession}_{machine}.stats"
    conda:
        "envs/seqkit.yaml"
    shell:
        """
        seqkit stats {input} -a -o {output}
        """

rule minimap2:
    input:
        read = ancient("combined/{accession}_{machine}.combined.fastq.gz"),
        mmul10 = ancient("downloads/mmul10.fna"),
    output:
        temp("alignments/{accession}_{machine}.sam")
    log:
        "logs/minimap2/log_{accession}_{machine}_alignment.log"
    benchmark:
        "benchmarks/minimap2/benchmark_{accession}_{machine}_alignment.txt"
    threads: 
        24
    params:
        read_type_pacbio = "map-hifi",
        read_type_nanopore = "map-ont"
    conda:
        "envs/minimap2.yaml"
    shell:
        """
        if [[ "{wildcards.machine}" == "pacbio" ]]; then
            minimap2 -ax {params.read_type_pacbio} -t {threads} {input.mmul10} {input.read} > {output} 2> {log}
        elif [[ "{wildcards.machine}" == "nanopore" ]]; then
            minimap2 -ax {params.read_type_nanopore} -t {threads} {input.mmul10} {input.read} > {output} 2> {log}
        fi
        """

rule extractMappedReads:
    input:
        ancient("alignments/{accession}_{machine}.sam")
    output:
        temp("alignments/extracted_{accession}_{machine}.bam")
    log:
        "logs/samtools/log_{accession}_{machine}_alignment.log",
    conda:
        "envs/samtools.yaml"
    threads:
        10
    shell:
        """
        samtools view -@ {threads} -bh -F4 {input} > {output} 2> {log}
        """

rule sortIndexBam:
    input:
        ancient("alignments/extracted_{accession}_{machine}.bam")
    output:
        sorted_bam = temp("alignments/sorted_{accession}_{machine}.bam"),
        index_bam = temp("alignments/sorted_{accession}_{machine}.bam.bai"),
    log:
        "logs/samtools/sort_index_log_{accession}_{machine}.log"
    conda:
        "envs/samtools.yaml"
    threads:
        10
    shell:
        """
        samtools sort -@ {threads} -o {output.sorted_bam} {input}
        samtools index -@ {threads} -o {output.index_bam} {output.sorted_bam} 2> {log}
        """

rule extractChr:
    input:
        sorted_bam = ancient("alignments/sorted_{accession}_{machine}.bam"),
        index_bam = ancient("alignments/sorted_{accession}_{machine}.bam.bai"),
        ref_report = ancient("downloads/reports/mmul10_assembly_report.txt"),
        chromosome_conversion = ancient("input/chromosome_conversion.json")
    output:
        "alignments/extracted_{chrs}_{accession}_{machine}.bam"
    params:
        chromosome=lambda wildcards, input: load_json_file("input/chromosome_conversion.json")[wildcards.chrs]
    log:
        "logs/samtools/extract_log_{chrs}_{accession}_{machine}.log"
    conda:
        "envs/samtools.yaml"
    threads:
        10
    shell:
        """
        samtools view -@ {threads} -b {input.sorted_bam} {params.chromosome} > {output} 2> {log}
        """


rule convertBamToFastQ:
    input:
        ancient("alignments/extracted_{chrs}_{accession}_{machine}.bam")
    output:
        "converted/{chrs}_{accession}_{machine}.fastq.gz"
    log:
        "logs/converted/log_converted_{chrs}_{accession}_{machine}.log"
    threads:
        10
    conda:
        "envs/samtools.yaml"
    shell:
        """
        samtools bam2fq -@ {threads} {input} | gzip -c > {output} 2> {log}
        """


rule extractChromosomseFromMmul10:
    input:
        ref = ancient("downloads/mmul10.fna")
    output:
        "downloads/mmul10_{chrs}.fna"
    shell:
        """
        number=$(echo {wildcards.chrs} | egrep -o "[0-9]")
        awk -v num="$number" '$0 ~ "chromosome " num {{flag=1;print;next}} /^>/{{flag=0}} flag' {input.ref} > {output}
        """


rule seqkitChromosomes:
    input:
        ancient("converted/{chrs}_{accession}_{machine}.fastq.gz")
    output:
        "QC/chromosome/{chrs}_{accession}_{machine}.stats"
    conda:
        "envs/seqkit.yaml"
    shell:
        """
        seqkit stats {input} -a -o {output}
        """


def chromosome_lengths(wildcards, chrs):
    chr_conversion = checkpoints.generate_json.get().output[0]
    chr_lengt = checkpoints.generate_json.get().output[1]
    chr_conversion_dict = load_json_file(chr_conversion)
    chr_lenght_dict = load_json_file(chr_lengt)
    return chr_lenght_dict[chr_conversion_dict[chrs]]


# rule flyeAssembly:
#     input:
#         ancient("converted/{chrs}_{accession}.fastq.gz")
#     output:
#         directory("flye/{chrs}_{accession}")
#     log:
#         "logs/assembly/flye/log_flye_{chrs}_{accession}.log"
#     benchmark:
#         "benchmarks/assembly/flye/benchmark_{chrs}_{accession}_flye.txt"
#     params:
#         read_type = "pacbio-hifi",
#         size = lambda wildcards: chromosome_lengths(wildcards, wildcards.chrs) 
#     threads:
#         24
#     conda:
#         "envs/flye.yaml"
#     shell:
#         """
#         flye --{params.read_type} {input} --out-dir {output} --genome-size {params.size} --asm-coverage 30 --threads {threads} 2> {log}
#         """


checkpoint hifiasmAssembly:
    input:
        pacbio = ancient("converted/{chrs}_{accession}_pacbio.fastq.gz"),
        nanopore = ancient("converted/{chrs}_{accession}_nanopore.fastq.gz") 
    output:
        directory("hifiasm/{chrs}_{accession}/"),
    params:
        prefix = "{chrs}_{accession}.asm",
        kmer = 54,
        window = 39
    threads:
        24
    conda:
        "envs/hifiasm.yaml"
    log:
        "logs/assembly/hifiasm/log_hifiasm_{chrs}_{accession}.log"
    shell:
        """
        mkdir -p {output}
        hifiasm -o {params.prefix} -t {threads} --ul {input.nanopore} {input.pacbio} 2> {log}
        mv {wildcards.chrs}_{wildcards.accession}* {output}
        """


rule getCoverageSamtools:
    input:
        ancient("alignments/extracted_{chrs}_{accession}_{machine}.bam")
    output:
        "coverage/coverage_{chrs}_{accession}_{machine}.txt"
    threads:
        10
    conda:
        "envs/samtools.yaml"
    shell:
        """
        samtools coverage  {input} -o {output}
        """


def get_hifiasm_assembly_files(wildcards):
    all_wildcards = glob_wildcards("hifiasm/{path}/{chrs}_{accession}.asm.bp.{haplo}_ctg.gfa")
    haplo_gfa_files = list(set(expand("hifiasm/{path}/{path}.asm.bp.{haplo}_ctg.gfa",
                            path=all_wildcards.path,
                            haplo=all_wildcards.haplo)))
    return haplo_gfa_files


rule genHaplo:
    input:
        ancient(get_hifiasm_assembly_files)
    output:
        "hifiasm_{accession}.txt"
    shell:
        """
        echo {input} > {output}
        """



rule gfaToFasta:
    input:
        gfa = lambda wildcards: checkpoints.hifiasmAssembly.get(**wildcards).output[0] + "/{chrs}_{accession}.asm.bp.{haplo}_ctg.gfa"
    output:
        "converted/gfatofasta/{chrs}_{accession}_{haplo}.fasta"
    conda:
        "envs/gfatools.yaml"
    shell:
        """
        gfatools gfa2fa {input} > {output}       
        """


rule scaffoldAssemlby:
    input:
        file = ancient("converted/gfatofasta/{chrs}_{accession}_{haplo}.fasta"),
        ref = ancient("downloads/mmul10.fna")
    output:
        "scaffold/{chrs}_{accession}_{haplo}/ragtag.scaffold.fasta"
    params:
        output_dir = "scaffold/{chrs}_{accession}_{haplo}"
    threads:
        24
    log:
        "logs/scaffholding/log_scaffholding_{chrs}_{accession}_{haplo}.log"
    conda:
        "envs/ragtag.yaml"
    shell:
        """
        ragtag.py scaffold -o {params.output_dir} -t {threads} {input.ref} {input.file} 2> {log}
        """


# rule polishScaffold:
#     input:
#         scaffold = ancient("scaffold/{chrs}_{accession}_{haplo}/ragtag.scaffold.fasta")
#         chr_fasta = ancient("converted/{chrs}_{accession}.fastq.gz")
#     output:
#         bam_file = "alignments/scaffold/mapped_{chrs}_{accession}_{haplo}.bam",
#         bai_file = "alignments/scaffold/mapped_{chrs}_{accession}_{haplo}.bam.bai"
#     params:
#         sam_file = "alignments/scaffold/mapped_{chrs}_{accession}_{haplo}.sam"
#         memory = "Xmx32G"
#     conda:
#         "envs/polishing.yaml"
#     shell:
#         """
#         minimap2 -ax map-hifi -t 24  {input.scaffold} {input.chr_fasta} > {params.sam_file}
#         samtools sort -@ 8 -o {output.bam_file} {params.sam_file}
#         samtools index {output.bai_file}
#         pilon -{params.memory} --genome {input.scaffold} --pacbio {outpu} --output pilon_polished --fix all --changes --vcf
#         """



rule downloadFlankingGenes:
    output:
        "flanking/{fgene}/ncbi_dataset/data/gene.fna"
    conda:
        "envs/flanking.yaml"
    shell:
        """
        mkdir -p flanking/{wildcards.fgene}
        cd flanking/{wildcards.fgene}
        datasets download gene symbol {wildcards.fgene} --taxon macaca mulatta --include gene --filename {wildcards.fgene}.zip
        unzip {wildcards.fgene}.zip
        """



rule combineFlankingGenes:
    input:
        ancient(expand("flanking/{fgene}/ncbi_dataset/data/gene.fna", fgene=FLANKING_GENES))
    output:
        "flanking/all_flanking_genes.fna"
    shell:
        """
        > {output}
        for file in {input}; do
            header=$(head -1 "$file" | egrep "^>" | awk '{{print $2":" $5":"$NF}}' | tr -d '[]')
            sequence=$(cat "$file" | egrep -v "^>")
            echo -e ">$header\n$sequence" >> {output}
        done
        """


def chromosomes_file(wildcards):
    chrom_file = checkpoints.generate_json.get().output[0]
    chr_conversion = load_json_file(chrom_file)
    chromosomes = list(chr_conversion.keys())
    return expand("converted/gfatofasta/{chrs}_{accession}_{chosen}.p.fasta", chrs=chromosomes, accession=wildcards.accession, chosen=["hap1", "hap2"])


rule combineChromosomes:
    input:
        chromosomes_file 
    output:
        temp("combined/{accession}_combined_chromosomes.fasta")
    shell:
        """
        cat {input} >> {output}
        """


rule mapFlankingGenes:
    input:
        reads = "combined/{accession}_combined_chromosomes.fasta",
        flanking_genes = "flanking/all_flanking_genes.fna"
    output:
        sam_file = "flank_aligment/{accession}_flank_aligned_chromosomes.sam",
        info = "QC/flanking/{accession}_flank_aligned_info.csv"
    conda:
        "envs/minimap2.yaml"
    threads:
        24
    shell:
        """
        minimap2 -ax splice -t {threads} {input.reads} {input.flanking_genes} > {output.sam_file}
        cat {output.sam_file} | egrep -v "@" | cut -f1-4 | sort -k 3 > {output.info}
        """

checkpoint contigFiles:
    input:
        contig_file = "QC/flanking/EAW_flank_aligned_info.csv",
        location_file = "input/locations.txt"
    output:
        output_dir = directory("contig/")
    script:
        "scripts/flanking_genes.py" 

def get_contig_files(wildcards):
    contig = checkpoints.contigFiles.get().output[0]
    return os.path.join(contig, "{chrs}_{accession}_{combi}.fasta")

rule mapContigFiles:
    input:
        contig_file = get_contig_files
    output:
        "alignments/flanking/{chrs}_{accession}_{combi}.sam"
    params:
        mmul10_chrom = lambda wildcards: wildcards.chrs + "_mmul10.fa"
    conda:
        "envs/minimap2.yaml"
    threads:
        10
    shell:
        """
        minimap2 -x asm5 -t {threads} downloads/{params.mmul10_chrom} {input.contig_file} > {output}
        """


rule BUSCODownloadDataset:
    input:
        ancient("converted/gfatofasta/{chrs}_{accession}_{haplo}.fasta")
    output:
        directory("BUSCO/{chrs}_{accession}_{haplo}")
    params:
        dataset = "primates_odb10"
    conda:
        "envs/busco.yaml"
    log:
        "logs/BUSCO/log_busco_{chrs}_{accession}_{haplo}.log"
    shell:
        """
        busco -i {input} -l {params.dataset} -o {output} -m genome 2> {log}
        """
        
        

# Input function to handle output of checkpoint
def intermediate_file(wildcards):
    checkpoint_output = checkpoints.split_fastq.get(accession=wildcards.accession, machine=wildcards.machine).output[0]
    chrom_file = checkpoints.generate_json.get().output[0]
    chr_conversion = load_json_file(chrom_file)
    haplotypes = ["hap1.p", "hap2.p", "p"]
    chromosomes = list(chr_conversion.keys())
    parts = glob_wildcards(os.path.join(checkpoint_output, "{accession}_{machine}.fastq.gz"))
    hifiasm_paths = expand("hifiasm/{chrs}_{accession}/", chrs=chromosomes, accession=wildcards.accession)
    # flye_path = expand("flye/{chrs}_{accession}", chrs=chromosomes, accession=wildcards.accession)
    coverage_path = expand("coverage/coverage_{chrs}_{accession}_{machine}.txt", chrs=chromosomes, accession=wildcards.accession, machine=wildcards.machine)
    raw_path = expand("QC/raw/{accession}_{machine}.stats", accession=wildcards.accession, machine=wildcards.machine)
    filtered_path = expand("QC/filtered/filtered_{accession}_{machine}.stats", accession=wildcards.accession, machine=wildcards.machine)
    chrs_path = expand("QC/chromosome/{chrs}_{accession}_{machine}.stats", chrs=chromosomes, accession=wildcards.accession, machine=wildcards.machine)
    scaffold_path = expand("scaffold/{chrs}_{accession}_{haplo}/ragtag.scaffold.fasta", chrs=chromosomes, accession=wildcards.accession, haplo=haplotypes)
    # busco_path = expand("BUSCO/{chrs}_{accession}_{haplo}", chrs=chromosomes, accession=wildcards.accession, haplo=haplotypes)
    contig_prefix = checkpoints.contigFiles.get().output[0]
    TRASH, COMBI = glob_wildcards(os.path.join(contig_prefix, "{trash}_EAW_{combi}.fasta"))
    contig = expand("alignments/flanking/{chrs}_{accession}_{combi}.sam", chrs=chromosomes, accession=wildcards.accession, combi=COMBI)
    all_paths = hifiasm_paths + coverage_path + raw_path + filtered_path + chrs_path + ["hifiasm_{accession}.txt"] + scaffold_path + ["flank_aligment/{accession}_flank_aligned_chromosomes.sam"] + contig
    return all_paths


# Rule to utilize the split FASTQ files
rule use_split_files:
    input:
        intermediate_file
    output:
        "final_{accession}_{machine}.txt"
    shell:
        """
        echo {input} | tr ' ' '\n' > {output}
        """
