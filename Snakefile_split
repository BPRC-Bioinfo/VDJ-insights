import os
import pandas as pd
from scripts.pipeline import *
import json
current = os.getcwd()

# ACCESSION = [item for sublist in glob_wildcards("downloads/{accession}.fastq.gz") for item in sublist]
# print("ACCESSION USED:", ACCESSION)


input_file = fetchall_args_input_file()
ids = get_ids(f"input/{input_file}")


if not os.path.exists(f"{current}/downloads"):
    os.makedirs(f"{current}/downloads")

files = [f for f in os.listdir(f"{current}/downloads") if f.startswith("SRR")]
if len(ids.keys()) > len(files):
    sra_download = fetchall_args_sra_download()
else:
    sra_download = "wget"





# Target rule specifying the desired final output
rule all:
    input:
        expand("processed_{accession}.txt", accession=ids.keys())


# Checkpoint for dynamically splitting the FASTQ file
checkpoint split_fastq:
    input:
        fastq="downloads/{accession}.fastq.gz"
    output:
        directory("split_files/{accession}/")        
    conda:
        "envs/seqkit.yaml"
    shell:
        """
        # your shell commands for splitting the file
        mkdir -p {output}

        #run seqkit split2       
        seqkit split2 -s 1000000 -O {output} {input.fastq} 
        """


# Input function to handle output of checkpoint
def getSplitFastqFiles(wildcards):
    checkpoint_output = checkpoints.split_fastq.get(accession=wildcards.accession).output[0]
    parts = glob_wildcards(os.path.join(checkpoint_output, "{accession}.part_{i}.fastq.gz")).i
    
    expanded_paths = expand("split_files/{accession}/{accession}.part_{i}.stats",
                            accession=wildcards.accession,
                            i=parts)
    return expanded_paths


rule rawStats:
    input:
        "split_files/{accession}/{accession}.part_{i}.fastq.gz"
    output:
        "split_files/{accession}/{accession}.part_{i}.stats"
    conda:
        "envs/seqkit.yaml"
    shell:
        """
        seqkit stat {input} > {output}
        """

# Rule for initial QC
rule seqkit:
    input:
        getSplitFastqFiles
    output:
        "results_{accession}.txt",
    shell:
        """
        cat {input} > {output}
        """

# Filter rule for removing adaptor for pacbio reads with seqkit rmdup.
rule pbAdaptFilt:
    input: 
        "split_files/{accession}/{accession}.part_{i}.fastq.gz"
    output: 
        pbfilt = temp("split_files/{accession}/pb/pb_filtered_{accession}.part_{i}.filt.fastq.gz")
    log:
        "logs/adaptor/log_{accession}_pb.part_{i}.log"
    benchmark:
        "benchmarks/adaptfilt/benchmark_{accession}_pb.part_{i}.txt"
    params:
        filt = "split_files/{accession}/pb/{accession}.part_{i}.filt.fastq.gz" ,
        input_dir = "split_files/{accession}",
    singularity:
        "docker://australianbiocommons/hifiadapterfilt"
    shell:
        """
        cd {params.input_dir}
        bash pbadapterfilt.sh -o pb -p {wildcards.accession}
        cd ../../
        mv {params.filt} {output.pbfilt}
        """

# Filter rule for removing adaptor for pacbio hifi reads with seqkit.
rule hifiAdaptFilt:
    input: 
        "split_files/{accession}/pb/pb_filtered_{accession}.part_{i}.filt.fastq.gz"
    output: 
        filt = temp("split_files/{accession}/hifi/hifi_filtered_{accession}.part_{i}.fastq.gz")
    log:
        "logs/adaptor/log_{accession}_hifi.part_{i}.log"
    benchmark:
        "benchmarks/adaptfilt/benchmark_{accession}_hifi.part_{i}.txt"
    params:
        input_dir = "split_files/{accession}/pb",
        output_dir = "hifi",
        hififilt = "split_files/{accession}/pb/hifi/pb_filtered_{accession}.part_{i}.filt.filt.fastq.gz",
    singularity:
        "docker://australianbiocommons/hifiadapterfilt"
    shell:
        """
        cd {params.input_dir}
        bash hifiadapterfilt.sh -o {params.output_dir} -p pb_filtered_{wildcards.accession}
        cd ../../../
        mv {params.hififilt} {output.filt} 
        """

rule filteredReads:
    input:
        "split_files/{accession}/hifi/hifi_filtered_{accession}.part_{i}.fastq.gz"
    output:
        "split_files/{accession}/cleaned/filtered_{accession}.part_{i}.fastq.gz"
    log:
        "logs/seqkit/filterd/log_{accession}_filterd.part_{i}.log"
    conda:
        "envs/seqkit.yaml"
    shell:
        """
        seqkit seq {input} -m 5000 -o {output} 
        """

# QC rule for getting statistics for filterd reads with seqkit stats.
rule seqkitFiltered:
    input:
        ancient("split_files/{accession}/cleaned/filtered_{accession}.part_{i}.fastq.gz")
    output:
        "split_files/{accession}/filtered_{accession}.part_{i}.stats"
    conda:
        "envs/seqkit.yaml"
    shell:
        """
        seqkit stats {input} -a -o {output} 2> {log}
        """

def getProcessedStatsFiles(wildcards):
    checkpoint_output = checkpoints.split_fastq.get(accession=wildcards.accession).output[0]
    parts = glob_wildcards(os.path.join(checkpoint_output, "{accession}.part_{i}.fastq.gz")).i
    
    expanded_paths = expand("split_files/{accession}/filtered_{accession}.part_{i}.stats",
                            accession=wildcards.accession,
                            i=parts)
    return expanded_paths


rule processedStats:
    input:
        getProcessedStatsFiles
    output:
        "processed_{accession}.txt"
    shell:
        """
        cat {input} > {output}
        """

'''

 
rule downloadMmul10:
    output:
        ref_report = "downloads/reports/mmul10_assembly_report.txt",
        ref = "downloads/mmul10.fna",
        chr_length = "input/chromosome_lengths.json",
        chr_conversion = "input/chromosome_conversion.json"
    params:
        zipped_ref = "downloads/mmul10.fna.gz"
    shell:
        """
        wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/003/339/765/GCA_003339765.3_Mmul_10/GCA_003339765.3_Mmul_10_assembly_report.txt -P reports -O {output.ref_report}
        wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/003/339/765/GCA_003339765.3_Mmul_10/GCA_003339765.3_Mmul_10_genomic.fna.gz -O {params.zipped_ref}
        gunzip {params.zipped_ref}
        python -c "from scripts.pipeline import fetch_chromosome; fetch_chromosome()"
        python -c "from scripts.pipeline import cal_chr_length; cal_chr_length()"
        """









# # Input function to handle output of checkpoint
# def get_split_files(wildcards):
#     checkpoint_output = checkpoints.split_fastq.get(accession=wildcards.accession).output[0]
#     accession = wildcards.accession
#     i_values = glob_wildcards(os.path.join(checkpoint_output, "sra_{accession}.part_{i}.fastq.gz")).i
    
#     expanded_paths = expand("split_files/{accession}/sra_{accession}.part_{i}.fastq.gz",
#                             accession=wildcards.accession,
#                             i=i_values)
#     return expanded_paths


# # Rule to utilize the split FASTQ files
# rule use_split_files:
#     input:
#         get_split_files  # Utilize the input function here
#     output:
#         "results_{accession}.txt"
#     shell:
#         """
#         echo {input} | tr ' ' '\n' > {output}
#         """
'''
